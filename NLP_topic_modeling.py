# -*- coding: utf-8 -*-
"""Assignment_NLP_2_Sundar Singh.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t3tK0obE4fvI7SPTMPKAXeyr87Tr9bzg
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import re

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/NLP/K8 Reviews v0.2.csv")

df

df.info()

df.sentiment.value_counts()

df.sentiment.value_counts(normalize=True).mul(100).round(2)

sns.countplot(df['sentiment'])
plt.title('Count of the review sentiments')
plt.show()

"""# 1. Normalize case"""

[i.lower() for i in df.review][14674]

norm_review = [i.lower() for i in df.review]

"""# Task 2. Tokenize (using word_tokenize from NLTK)"""

#Tokenizing 
import nltk
#nltk.download('punkt')
from nltk.tokenize import word_tokenize, sent_tokenize
token_review = [word_tokenize(i) for i in norm_review]
print(token_review)

"""# Task 3. POS tagging using the NLTK pos tagger"""

#nltk.download('averaged_perceptron_tagger')
pos_review = [nltk.pos_tag(i) for i in token_review]
print(pos_review[0])

"""## Task 4. For the topic model, we would want 

to include only nouns
 - First, find out all the POS tags that correspond to nouns
 - Limit the data to only terms with these tags

"""

noun_review = []
for i in pos_review:
  noun_review.append([j for j in i if re.search("NN.+", j[1])])
noun_review[0]

"""## Task  5. Lemmatize
 - you want different forms of the terms to be treated as one
 - don't worry about providing POS tag to lemmatizer for now
"""

nltk.download('wordnet')

from nltk.stem import WordNetLemmatizer
lem = WordNetLemmatizer()
lem_reviews = []
for i in noun_review:
  lem_reviews.append([lem.lemmatize(word[0]) for word in i])

lem_reviews[0]

#def word_lem(text):
#  return WordNetLemmatizer().lemmatize(text, pos='n')

"""# Task 6. Remove stop words and punctuation (if there are any at all after the POS tagging)"""

nltk.download('stopwords')

from string import punctuation
from nltk.corpus import stopwords
stop_nltk = stopwords.words("english")

stop_updated = stop_nltk + list(punctuation) + ["..!"] + [":)"]
reviews_sw_removed=[]
for sent in lem_reviews:
    reviews_sw_removed.append([term for term in sent if term not in stop_updated])

reviews_sw_removed[0]

"""## Task 7. Create a topic model using LDA on the cleaned up data with 12 topics
 - what is the coherence of the model?
 
 Use gensim for this task
"""

import gensim
import gensim.corpora as corpora
from gensim.models import CoherenceModel
from gensim.models import ldamodel

x = gensim.utils.simple_preprocess(df['review'][300])
print(x)

print(gensim.parsing.preprocessing.STOPWORDS)

"""### All preprocess steps done by small code"""

def preprocess(text):
  result=[]
  for token in gensim.utils.simple_preprocess(text):
    if token not in gensim.parsing.preprocessing.STOPWORDS and len(token)>3:
      result.append(WordNetLemmatizer().lemmatize(token, pos='n'))
  return result

print(preprocess(df['review'][300]))

preprocessed_reviews = []
for i in df.review:
  preprocessed_reviews.append(preprocess(i))

print(preprocessed_reviews[:10])

dictionary = gensim.corpora.Dictionary(preprocessed_reviews)

dictionary.keys()[:5]

#print a few words in the dictionary
count = 0
for a,b in dictionary.iteritems():
    print(a,b)
    count = count + 1
    if count > 7:
        break

bow_corpus = [dictionary.doc2bow(doc) for doc in preprocessed_reviews]

print(bow_corpus)

#apply the gensim LDA model and generate 4 topics from the corpus
gensim.models.ldamodel.LdaModel(corpus=bow_corpus,
                                           id2word=dictionary,
                                           num_topics=4, 
                                           random_state=42,
                                           passes=10,
                                           per_word_topics=True)

pprint(lda_model.print_topics())

'''
For each topic, explore each word and its relative weight in the topic
'''

for idx,topic in lda_model.print_topics(-1,num_words=15):
    print("Topic: {} \nWords: {}".format(idx, topic ))
    print("\n")

#import Coherence model from gensim
from gensim.models import CoherenceModel
#compute coherence score
lda_model_coherence = CoherenceModel(model=lda_model,texts=preprocessed_reviews,dictionary=dictionary,
                                    coherence='c_v')
coherence_lda = lda_model_coherence.get_coherence()
print('\nCoherence Score:',coherence_lda)

"""### Task 8. Analyze the topics, which pairs of topics can be combined?
 - you can assume that if a pair of topics has very similar top terms, they are very close and can be combined
"""

## Pair of topics that similar terms
** Topic 0,7,9 and 10 possibly talks about 'performance'
Topic 3 &5 closely talks about 'battery related issues'
Topic 4 and 8 vaguely talks about 'Screen'**

"""# Task 9. Create topic model using LDA with what you think is the optimal number of topics

 . is the coherence better now?
"""

# Build LDA model
lda_model8 = gensim.models.ldamodel.LdaModel(corpus=bow_corpus,
                                           id2word=dictionary,
                                           num_topics=8, 
                                           random_state=42,
                                           passes=10,
                                           per_word_topics=True)

# Compute Coherence Score
coherence_model_lda = CoherenceModel(model=lda_model8, texts=preprocessed_reviews, dictionary=dictionary, coherence='c_v')
coherence_lda = coherence_model_lda.get_coherence()
print('\nCoherence Score: ', coherence_lda)

"""# Task 10. The business finally needs to be able to interpret the topics
name each of the identified topics
create a table with the topic name and the top 10 terms in each to present to business
"""

x = lda_model8.show_topics(formatted=False)
topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]

for topic,words in topics_words:
    print(str(topic)+ "::"+ str(words))
print()

#possible topics from terms present

#Topic0 = issues
#Topic1 = mobile working condition
#Topic2 = Quality
#Topic3 = phone performance
#Topic4 = update
#Topic5 = battery related issues
#Topic6 = camera quality
#Topic7 = Amazon service